Some weights of the model checkpoint at rinna/japanese-gpt-neox-3.6b were not used when initializing GPTNeoXModel: ['embed_out.weight']
- This IS expected if you are initializing GPTNeoXModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing GPTNeoXModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
{'Arg': 0, 'Arg0': 1, 'Arg1': 2, 'Arg2': 3, 'Arg3': 4, 'Arg4': 5, 'Arg5': 6, 'ArgA': 7, 'ArgM': 8, 'ArgM2': 9, 'ArgM_ADV': 10, 'ArgM_AND': 11, 'ArgM_BUT': 12, 'ArgM_CAU': 13, 'ArgM_CMP': 14, 'ArgM_CND': 15, 'ArgM_CRT': 16, 'ArgM_DIR': 17, 'ArgM_EXT': 18, 'ArgM_GOL': 19, 'ArgM_LOC': 20, 'ArgM_MDF': 21, 'ArgM_MNR': 22, 'ArgM_MNS': 23, 'ArgM_NEG': 24, 'ArgM_PRP': 25, 'ArgM_PRX': 26, 'ArgM_REC': 27, 'ArgM_SCP': 28, 'ArgM_SPK': 29, 'ArgM_TMP': 30, 'F-A': 31, 'F-P': 32, 'V': 33, 'O': 34, 'N': 35} 

MAX_TOKEN = 206, MAX_LENGTH = 192, MAX_ARGUMENT_SEQUENCE_LENGTH = 30


No dependency data
42022
base_model.model.rinna.embed_in.weight False
base_model.model.rinna.layers.0.input_layernorm.weight False
base_model.model.rinna.layers.0.input_layernorm.bias False
base_model.model.rinna.layers.0.post_attention_layernorm.weight False
base_model.model.rinna.layers.0.post_attention_layernorm.bias False
base_model.model.rinna.layers.0.attention.query_key_value.weight False
base_model.model.rinna.layers.0.attention.query_key_value.bias False
base_model.model.rinna.layers.0.attention.query_key_value.lora_A.default.weight False
base_model.model.rinna.layers.0.attention.query_key_value.lora_B.default.weight False
base_model.model.rinna.layers.0.attention.dense.weight False
base_model.model.rinna.layers.0.attention.dense.bias False
base_model.model.rinna.layers.0.mlp.dense_h_to_4h.weight False
base_model.model.rinna.layers.0.mlp.dense_h_to_4h.bias False
base_model.model.rinna.layers.0.mlp.dense_4h_to_h.weight False
base_model.model.rinna.layers.0.mlp.dense_4h_to_h.bias False
base_model.model.rinna.layers.1.input_layernorm.weight False
base_model.model.rinna.layers.1.input_layernorm.bias False
base_model.model.rinna.layers.1.post_attention_layernorm.weight False
base_model.model.rinna.layers.1.post_attention_layernorm.bias False
base_model.model.rinna.layers.1.attention.query_key_value.weight False
base_model.model.rinna.layers.1.attention.query_key_value.bias False
base_model.model.rinna.layers.1.attention.query_key_value.lora_A.default.weight False
base_model.model.rinna.layers.1.attention.query_key_value.lora_B.default.weight False
base_model.model.rinna.layers.1.attention.dense.weight False
base_model.model.rinna.layers.1.attention.dense.bias False
base_model.model.rinna.layers.1.mlp.dense_h_to_4h.weight False
base_model.model.rinna.layers.1.mlp.dense_h_to_4h.bias False
base_model.model.rinna.layers.1.mlp.dense_4h_to_h.weight False
base_model.model.rinna.layers.1.mlp.dense_4h_to_h.bias False
base_model.model.rinna.layers.2.input_layernorm.weight False
base_model.model.rinna.layers.2.input_layernorm.bias False
base_model.model.rinna.layers.2.post_attention_layernorm.weight False
base_model.model.rinna.layers.2.post_attention_layernorm.bias False
base_model.model.rinna.layers.2.attention.query_key_value.weight False
base_model.model.rinna.layers.2.attention.query_key_value.bias False
base_model.model.rinna.layers.2.attention.query_key_value.lora_A.default.weight False
base_model.model.rinna.layers.2.attention.query_key_value.lora_B.default.weight False
base_model.model.rinna.layers.2.attention.dense.weight False
base_model.model.rinna.layers.2.attention.dense.bias False
base_model.model.rinna.layers.2.mlp.dense_h_to_4h.weight False
base_model.model.rinna.layers.2.mlp.dense_h_to_4h.bias False
base_model.model.rinna.layers.2.mlp.dense_4h_to_h.weight False
base_model.model.rinna.layers.2.mlp.dense_4h_to_h.bias False
base_model.model.rinna.layers.3.input_layernorm.weight False
base_model.model.rinna.layers.3.input_layernorm.bias False
base_model.model.rinna.layers.3.post_attention_layernorm.weight False
base_model.model.rinna.layers.3.post_attention_layernorm.bias False
base_model.model.rinna.layers.3.attention.query_key_value.weight False
base_model.model.rinna.layers.3.attention.query_key_value.bias False
base_model.model.rinna.layers.3.attention.query_key_value.lora_A.default.weight False
base_model.model.rinna.layers.3.attention.query_key_value.lora_B.default.weight False
base_model.model.rinna.layers.3.attention.dense.weight False
base_model.model.rinna.layers.3.attention.dense.bias False
base_model.model.rinna.layers.3.mlp.dense_h_to_4h.weight False
base_model.model.rinna.layers.3.mlp.dense_h_to_4h.bias False
base_model.model.rinna.layers.3.mlp.dense_4h_to_h.weight False
base_model.model.rinna.layers.3.mlp.dense_4h_to_h.bias False
base_model.model.rinna.layers.4.input_layernorm.weight False
base_model.model.rinna.layers.4.input_layernorm.bias False
base_model.model.rinna.layers.4.post_attention_layernorm.weight False
base_model.model.rinna.layers.4.post_attention_layernorm.bias False
base_model.model.rinna.layers.4.attention.query_key_value.weight False
base_model.model.rinna.layers.4.attention.query_key_value.bias False
base_model.model.rinna.layers.4.attention.query_key_value.lora_A.default.weight False
base_model.model.rinna.layers.4.attention.query_key_value.lora_B.default.weight False
base_model.model.rinna.layers.4.attention.dense.weight False
base_model.model.rinna.layers.4.attention.dense.bias False
base_model.model.rinna.layers.4.mlp.dense_h_to_4h.weight False
base_model.model.rinna.layers.4.mlp.dense_h_to_4h.bias False
base_model.model.rinna.layers.4.mlp.dense_4h_to_h.weight False
base_model.model.rinna.layers.4.mlp.dense_4h_to_h.bias False
base_model.model.rinna.layers.5.input_layernorm.weight False
base_model.model.rinna.layers.5.input_layernorm.bias False
base_model.model.rinna.layers.5.post_attention_layernorm.weight False
base_model.model.rinna.layers.5.post_attention_layernorm.bias False
base_model.model.rinna.layers.5.attention.query_key_value.weight False
base_model.model.rinna.layers.5.attention.query_key_value.bias False
base_model.model.rinna.layers.5.attention.query_key_value.lora_A.default.weight False
base_model.model.rinna.layers.5.attention.query_key_value.lora_B.default.weight False
base_model.model.rinna.layers.5.attention.dense.weight False
base_model.model.rinna.layers.5.attention.dense.bias False
base_model.model.rinna.layers.5.mlp.dense_h_to_4h.weight False
base_model.model.rinna.layers.5.mlp.dense_h_to_4h.bias False
base_model.model.rinna.layers.5.mlp.dense_4h_to_h.weight False
base_model.model.rinna.layers.5.mlp.dense_4h_to_h.bias False
base_model.model.rinna.layers.6.input_layernorm.weight False
base_model.model.rinna.layers.6.input_layernorm.bias False
base_model.model.rinna.layers.6.post_attention_layernorm.weight False
base_model.model.rinna.layers.6.post_attention_layernorm.bias False
base_model.model.rinna.layers.6.attention.query_key_value.weight False
base_model.model.rinna.layers.6.attention.query_key_value.bias False
base_model.model.rinna.layers.6.attention.query_key_value.lora_A.default.weight False
base_model.model.rinna.layers.6.attention.query_key_value.lora_B.default.weight False
base_model.model.rinna.layers.6.attention.dense.weight False
base_model.model.rinna.layers.6.attention.dense.bias False
base_model.model.rinna.layers.6.mlp.dense_h_to_4h.weight False
base_model.model.rinna.layers.6.mlp.dense_h_to_4h.bias False
base_model.model.rinna.layers.6.mlp.dense_4h_to_h.weight False
base_model.model.rinna.layers.6.mlp.dense_4h_to_h.bias False
base_model.model.rinna.layers.7.input_layernorm.weight False
base_model.model.rinna.layers.7.input_layernorm.bias False
base_model.model.rinna.layers.7.post_attention_layernorm.weight False
base_model.model.rinna.layers.7.post_attention_layernorm.bias False
base_model.model.rinna.layers.7.attention.query_key_value.weight False
base_model.model.rinna.layers.7.attention.query_key_value.bias False
base_model.model.rinna.layers.7.attention.query_key_value.lora_A.default.weight False
base_model.model.rinna.layers.7.attention.query_key_value.lora_B.default.weight False
base_model.model.rinna.layers.7.attention.dense.weight False
base_model.model.rinna.layers.7.attention.dense.bias False
base_model.model.rinna.layers.7.mlp.dense_h_to_4h.weight False
base_model.model.rinna.layers.7.mlp.dense_h_to_4h.bias False
base_model.model.rinna.layers.7.mlp.dense_4h_to_h.weight False
base_model.model.rinna.layers.7.mlp.dense_4h_to_h.bias False
base_model.model.rinna.layers.8.input_layernorm.weight False
base_model.model.rinna.layers.8.input_layernorm.bias False
base_model.model.rinna.layers.8.post_attention_layernorm.weight False
base_model.model.rinna.layers.8.post_attention_layernorm.bias False
base_model.model.rinna.layers.8.attention.query_key_value.weight False
base_model.model.rinna.layers.8.attention.query_key_value.bias False
base_model.model.rinna.layers.8.attention.query_key_value.lora_A.default.weight False
base_model.model.rinna.layers.8.attention.query_key_value.lora_B.default.weight False
base_model.model.rinna.layers.8.attention.dense.weight False
base_model.model.rinna.layers.8.attention.dense.bias False
base_model.model.rinna.layers.8.mlp.dense_h_to_4h.weight False
base_model.model.rinna.layers.8.mlp.dense_h_to_4h.bias False
base_model.model.rinna.layers.8.mlp.dense_4h_to_h.weight False
base_model.model.rinna.layers.8.mlp.dense_4h_to_h.bias False
base_model.model.rinna.layers.9.input_layernorm.weight False
base_model.model.rinna.layers.9.input_layernorm.bias False
base_model.model.rinna.layers.9.post_attention_layernorm.weight False
base_model.model.rinna.layers.9.post_attention_layernorm.bias False
base_model.model.rinna.layers.9.attention.query_key_value.weight False
base_model.model.rinna.layers.9.attention.query_key_value.bias False
base_model.model.rinna.layers.9.attention.query_key_value.lora_A.default.weight False
base_model.model.rinna.layers.9.attention.query_key_value.lora_B.default.weight False
base_model.model.rinna.layers.9.attention.dense.weight False
base_model.model.rinna.layers.9.attention.dense.bias False
base_model.model.rinna.layers.9.mlp.dense_h_to_4h.weight False
base_model.model.rinna.layers.9.mlp.dense_h_to_4h.bias False
base_model.model.rinna.layers.9.mlp.dense_4h_to_h.weight False
base_model.model.rinna.layers.9.mlp.dense_4h_to_h.bias False
base_model.model.rinna.layers.10.input_layernorm.weight False
base_model.model.rinna.layers.10.input_layernorm.bias False
base_model.model.rinna.layers.10.post_attention_layernorm.weight False
base_model.model.rinna.layers.10.post_attention_layernorm.bias False
base_model.model.rinna.layers.10.attention.query_key_value.weight False
base_model.model.rinna.layers.10.attention.query_key_value.bias False
base_model.model.rinna.layers.10.attention.query_key_value.lora_A.default.weight False
base_model.model.rinna.layers.10.attention.query_key_value.lora_B.default.weight False
base_model.model.rinna.layers.10.attention.dense.weight False
base_model.model.rinna.layers.10.attention.dense.bias False
base_model.model.rinna.layers.10.mlp.dense_h_to_4h.weight False
base_model.model.rinna.layers.10.mlp.dense_h_to_4h.bias False
base_model.model.rinna.layers.10.mlp.dense_4h_to_h.weight False
base_model.model.rinna.layers.10.mlp.dense_4h_to_h.bias False
base_model.model.rinna.layers.11.input_layernorm.weight False
base_model.model.rinna.layers.11.input_layernorm.bias False
base_model.model.rinna.layers.11.post_attention_layernorm.weight False
base_model.model.rinna.layers.11.post_attention_layernorm.bias False
base_model.model.rinna.layers.11.attention.query_key_value.weight False
base_model.model.rinna.layers.11.attention.query_key_value.bias False
base_model.model.rinna.layers.11.attention.query_key_value.lora_A.default.weight False
base_model.model.rinna.layers.11.attention.query_key_value.lora_B.default.weight False
base_model.model.rinna.layers.11.attention.dense.weight False
base_model.model.rinna.layers.11.attention.dense.bias False
base_model.model.rinna.layers.11.mlp.dense_h_to_4h.weight False
base_model.model.rinna.layers.11.mlp.dense_h_to_4h.bias False
base_model.model.rinna.layers.11.mlp.dense_4h_to_h.weight False
base_model.model.rinna.layers.11.mlp.dense_4h_to_h.bias False
base_model.model.rinna.layers.12.input_layernorm.weight False
base_model.model.rinna.layers.12.input_layernorm.bias False
base_model.model.rinna.layers.12.post_attention_layernorm.weight False
base_model.model.rinna.layers.12.post_attention_layernorm.bias False
base_model.model.rinna.layers.12.attention.query_key_value.weight False
base_model.model.rinna.layers.12.attention.query_key_value.bias False
base_model.model.rinna.layers.12.attention.query_key_value.lora_A.default.weight False
base_model.model.rinna.layers.12.attention.query_key_value.lora_B.default.weight False
base_model.model.rinna.layers.12.attention.dense.weight False
base_model.model.rinna.layers.12.attention.dense.bias False
base_model.model.rinna.layers.12.mlp.dense_h_to_4h.weight False
base_model.model.rinna.layers.12.mlp.dense_h_to_4h.bias False
base_model.model.rinna.layers.12.mlp.dense_4h_to_h.weight False
base_model.model.rinna.layers.12.mlp.dense_4h_to_h.bias False
base_model.model.rinna.layers.13.input_layernorm.weight False
base_model.model.rinna.layers.13.input_layernorm.bias False
base_model.model.rinna.layers.13.post_attention_layernorm.weight False
base_model.model.rinna.layers.13.post_attention_layernorm.bias False
base_model.model.rinna.layers.13.attention.query_key_value.weight False
base_model.model.rinna.layers.13.attention.query_key_value.bias False
base_model.model.rinna.layers.13.attention.query_key_value.lora_A.default.weight False
base_model.model.rinna.layers.13.attention.query_key_value.lora_B.default.weight False
base_model.model.rinna.layers.13.attention.dense.weight False
base_model.model.rinna.layers.13.attention.dense.bias False
base_model.model.rinna.layers.13.mlp.dense_h_to_4h.weight False
base_model.model.rinna.layers.13.mlp.dense_h_to_4h.bias False
base_model.model.rinna.layers.13.mlp.dense_4h_to_h.weight False
base_model.model.rinna.layers.13.mlp.dense_4h_to_h.bias False
base_model.model.rinna.layers.14.input_layernorm.weight False
base_model.model.rinna.layers.14.input_layernorm.bias False
base_model.model.rinna.layers.14.post_attention_layernorm.weight False
base_model.model.rinna.layers.14.post_attention_layernorm.bias False
base_model.model.rinna.layers.14.attention.query_key_value.weight False
base_model.model.rinna.layers.14.attention.query_key_value.bias False
base_model.model.rinna.layers.14.attention.query_key_value.lora_A.default.weight False
base_model.model.rinna.layers.14.attention.query_key_value.lora_B.default.weight False
base_model.model.rinna.layers.14.attention.dense.weight False
base_model.model.rinna.layers.14.attention.dense.bias False
base_model.model.rinna.layers.14.mlp.dense_h_to_4h.weight False
base_model.model.rinna.layers.14.mlp.dense_h_to_4h.bias False
base_model.model.rinna.layers.14.mlp.dense_4h_to_h.weight False
base_model.model.rinna.layers.14.mlp.dense_4h_to_h.bias False
base_model.model.rinna.layers.15.input_layernorm.weight False
base_model.model.rinna.layers.15.input_layernorm.bias False
base_model.model.rinna.layers.15.post_attention_layernorm.weight False
base_model.model.rinna.layers.15.post_attention_layernorm.bias False
base_model.model.rinna.layers.15.attention.query_key_value.weight False
base_model.model.rinna.layers.15.attention.query_key_value.bias False
base_model.model.rinna.layers.15.attention.query_key_value.lora_A.default.weight False
base_model.model.rinna.layers.15.attention.query_key_value.lora_B.default.weight False
base_model.model.rinna.layers.15.attention.dense.weight False
base_model.model.rinna.layers.15.attention.dense.bias False
base_model.model.rinna.layers.15.mlp.dense_h_to_4h.weight False
base_model.model.rinna.layers.15.mlp.dense_h_to_4h.bias False
base_model.model.rinna.layers.15.mlp.dense_4h_to_h.weight False
base_model.model.rinna.layers.15.mlp.dense_4h_to_h.bias False
base_model.model.rinna.layers.16.input_layernorm.weight False
base_model.model.rinna.layers.16.input_layernorm.bias False
base_model.model.rinna.layers.16.post_attention_layernorm.weight False
base_model.model.rinna.layers.16.post_attention_layernorm.bias False
base_model.model.rinna.layers.16.attention.query_key_value.weight False
base_model.model.rinna.layers.16.attention.query_key_value.bias False
base_model.model.rinna.layers.16.attention.query_key_value.lora_A.default.weight False
base_model.model.rinna.layers.16.attention.query_key_value.lora_B.default.weight False
base_model.model.rinna.layers.16.attention.dense.weight False
base_model.model.rinna.layers.16.attention.dense.bias False
base_model.model.rinna.layers.16.mlp.dense_h_to_4h.weight False
base_model.model.rinna.layers.16.mlp.dense_h_to_4h.bias False
base_model.model.rinna.layers.16.mlp.dense_4h_to_h.weight False
base_model.model.rinna.layers.16.mlp.dense_4h_to_h.bias False
base_model.model.rinna.layers.17.input_layernorm.weight False
base_model.model.rinna.layers.17.input_layernorm.bias False
base_model.model.rinna.layers.17.post_attention_layernorm.weight False
base_model.model.rinna.layers.17.post_attention_layernorm.bias False
base_model.model.rinna.layers.17.attention.query_key_value.weight False
base_model.model.rinna.layers.17.attention.query_key_value.bias False
base_model.model.rinna.layers.17.attention.query_key_value.lora_A.default.weight False
base_model.model.rinna.layers.17.attention.query_key_value.lora_B.default.weight False
base_model.model.rinna.layers.17.attention.dense.weight False
base_model.model.rinna.layers.17.attention.dense.bias False
base_model.model.rinna.layers.17.mlp.dense_h_to_4h.weight False
base_model.model.rinna.layers.17.mlp.dense_h_to_4h.bias False
base_model.model.rinna.layers.17.mlp.dense_4h_to_h.weight False
base_model.model.rinna.layers.17.mlp.dense_4h_to_h.bias False
base_model.model.rinna.layers.18.input_layernorm.weight False
base_model.model.rinna.layers.18.input_layernorm.bias False
base_model.model.rinna.layers.18.post_attention_layernorm.weight False
base_model.model.rinna.layers.18.post_attention_layernorm.bias False
base_model.model.rinna.layers.18.attention.query_key_value.weight False
base_model.model.rinna.layers.18.attention.query_key_value.bias False
base_model.model.rinna.layers.18.attention.query_key_value.lora_A.default.weight False
base_model.model.rinna.layers.18.attention.query_key_value.lora_B.default.weight False
base_model.model.rinna.layers.18.attention.dense.weight False
base_model.model.rinna.layers.18.attention.dense.bias False
base_model.model.rinna.layers.18.mlp.dense_h_to_4h.weight False
base_model.model.rinna.layers.18.mlp.dense_h_to_4h.bias False
base_model.model.rinna.layers.18.mlp.dense_4h_to_h.weight False
base_model.model.rinna.layers.18.mlp.dense_4h_to_h.bias False
base_model.model.rinna.layers.19.input_layernorm.weight False
base_model.model.rinna.layers.19.input_layernorm.bias False
base_model.model.rinna.layers.19.post_attention_layernorm.weight False
base_model.model.rinna.layers.19.post_attention_layernorm.bias False
base_model.model.rinna.layers.19.attention.query_key_value.weight False
base_model.model.rinna.layers.19.attention.query_key_value.bias False
base_model.model.rinna.layers.19.attention.query_key_value.lora_A.default.weight False
base_model.model.rinna.layers.19.attention.query_key_value.lora_B.default.weight False
base_model.model.rinna.layers.19.attention.dense.weight False
base_model.model.rinna.layers.19.attention.dense.bias False
base_model.model.rinna.layers.19.mlp.dense_h_to_4h.weight False
base_model.model.rinna.layers.19.mlp.dense_h_to_4h.bias False
base_model.model.rinna.layers.19.mlp.dense_4h_to_h.weight False
base_model.model.rinna.layers.19.mlp.dense_4h_to_h.bias False
base_model.model.rinna.layers.20.input_layernorm.weight False
base_model.model.rinna.layers.20.input_layernorm.bias False
base_model.model.rinna.layers.20.post_attention_layernorm.weight False
base_model.model.rinna.layers.20.post_attention_layernorm.bias False
base_model.model.rinna.layers.20.attention.query_key_value.weight False
base_model.model.rinna.layers.20.attention.query_key_value.bias False
base_model.model.rinna.layers.20.attention.query_key_value.lora_A.default.weight False
base_model.model.rinna.layers.20.attention.query_key_value.lora_B.default.weight False
base_model.model.rinna.layers.20.attention.dense.weight False
base_model.model.rinna.layers.20.attention.dense.bias False
base_model.model.rinna.layers.20.mlp.dense_h_to_4h.weight False
base_model.model.rinna.layers.20.mlp.dense_h_to_4h.bias False
base_model.model.rinna.layers.20.mlp.dense_4h_to_h.weight False
base_model.model.rinna.layers.20.mlp.dense_4h_to_h.bias False
base_model.model.rinna.layers.21.input_layernorm.weight False
base_model.model.rinna.layers.21.input_layernorm.bias False
base_model.model.rinna.layers.21.post_attention_layernorm.weight False
base_model.model.rinna.layers.21.post_attention_layernorm.bias False
base_model.model.rinna.layers.21.attention.query_key_value.weight False
base_model.model.rinna.layers.21.attention.query_key_value.bias False
base_model.model.rinna.layers.21.attention.query_key_value.lora_A.default.weight False
base_model.model.rinna.layers.21.attention.query_key_value.lora_B.default.weight False
base_model.model.rinna.layers.21.attention.dense.weight False
base_model.model.rinna.layers.21.attention.dense.bias False
base_model.model.rinna.layers.21.mlp.dense_h_to_4h.weight False
base_model.model.rinna.layers.21.mlp.dense_h_to_4h.bias False
base_model.model.rinna.layers.21.mlp.dense_4h_to_h.weight False
base_model.model.rinna.layers.21.mlp.dense_4h_to_h.bias False
base_model.model.rinna.layers.22.input_layernorm.weight False
base_model.model.rinna.layers.22.input_layernorm.bias False
base_model.model.rinna.layers.22.post_attention_layernorm.weight False
base_model.model.rinna.layers.22.post_attention_layernorm.bias False
base_model.model.rinna.layers.22.attention.query_key_value.weight False
base_model.model.rinna.layers.22.attention.query_key_value.bias False
base_model.model.rinna.layers.22.attention.query_key_value.lora_A.default.weight False
base_model.model.rinna.layers.22.attention.query_key_value.lora_B.default.weight False
base_model.model.rinna.layers.22.attention.dense.weight False
base_model.model.rinna.layers.22.attention.dense.bias False
base_model.model.rinna.layers.22.mlp.dense_h_to_4h.weight False
base_model.model.rinna.layers.22.mlp.dense_h_to_4h.bias False
base_model.model.rinna.layers.22.mlp.dense_4h_to_h.weight False
base_model.model.rinna.layers.22.mlp.dense_4h_to_h.bias False
base_model.model.rinna.layers.23.input_layernorm.weight False
base_model.model.rinna.layers.23.input_layernorm.bias False
base_model.model.rinna.layers.23.post_attention_layernorm.weight False
base_model.model.rinna.layers.23.post_attention_layernorm.bias False
base_model.model.rinna.layers.23.attention.query_key_value.weight False
base_model.model.rinna.layers.23.attention.query_key_value.bias False
base_model.model.rinna.layers.23.attention.query_key_value.lora_A.default.weight False
base_model.model.rinna.layers.23.attention.query_key_value.lora_B.default.weight False
base_model.model.rinna.layers.23.attention.dense.weight False
base_model.model.rinna.layers.23.attention.dense.bias False
base_model.model.rinna.layers.23.mlp.dense_h_to_4h.weight False
base_model.model.rinna.layers.23.mlp.dense_h_to_4h.bias False
base_model.model.rinna.layers.23.mlp.dense_4h_to_h.weight False
base_model.model.rinna.layers.23.mlp.dense_4h_to_h.bias False
base_model.model.rinna.layers.24.input_layernorm.weight False
base_model.model.rinna.layers.24.input_layernorm.bias False
base_model.model.rinna.layers.24.post_attention_layernorm.weight False
base_model.model.rinna.layers.24.post_attention_layernorm.bias False
base_model.model.rinna.layers.24.attention.query_key_value.weight False
base_model.model.rinna.layers.24.attention.query_key_value.bias False
base_model.model.rinna.layers.24.attention.query_key_value.lora_A.default.weight False
base_model.model.rinna.layers.24.attention.query_key_value.lora_B.default.weight False
base_model.model.rinna.layers.24.attention.dense.weight False
base_model.model.rinna.layers.24.attention.dense.bias False
base_model.model.rinna.layers.24.mlp.dense_h_to_4h.weight False
base_model.model.rinna.layers.24.mlp.dense_h_to_4h.bias False
base_model.model.rinna.layers.24.mlp.dense_4h_to_h.weight False
base_model.model.rinna.layers.24.mlp.dense_4h_to_h.bias False
base_model.model.rinna.layers.25.input_layernorm.weight False
base_model.model.rinna.layers.25.input_layernorm.bias False
base_model.model.rinna.layers.25.post_attention_layernorm.weight False
base_model.model.rinna.layers.25.post_attention_layernorm.bias False
base_model.model.rinna.layers.25.attention.query_key_value.weight False
base_model.model.rinna.layers.25.attention.query_key_value.bias False
base_model.model.rinna.layers.25.attention.query_key_value.lora_A.default.weight False
base_model.model.rinna.layers.25.attention.query_key_value.lora_B.default.weight False
base_model.model.rinna.layers.25.attention.dense.weight False
base_model.model.rinna.layers.25.attention.dense.bias False
base_model.model.rinna.layers.25.mlp.dense_h_to_4h.weight False
base_model.model.rinna.layers.25.mlp.dense_h_to_4h.bias False
base_model.model.rinna.layers.25.mlp.dense_4h_to_h.weight False
base_model.model.rinna.layers.25.mlp.dense_4h_to_h.bias False
base_model.model.rinna.layers.26.input_layernorm.weight False
base_model.model.rinna.layers.26.input_layernorm.bias False
base_model.model.rinna.layers.26.post_attention_layernorm.weight False
base_model.model.rinna.layers.26.post_attention_layernorm.bias False
base_model.model.rinna.layers.26.attention.query_key_value.weight False
base_model.model.rinna.layers.26.attention.query_key_value.bias False
base_model.model.rinna.layers.26.attention.query_key_value.lora_A.default.weight False
base_model.model.rinna.layers.26.attention.query_key_value.lora_B.default.weight False
base_model.model.rinna.layers.26.attention.dense.weight False
base_model.model.rinna.layers.26.attention.dense.bias False
base_model.model.rinna.layers.26.mlp.dense_h_to_4h.weight False
base_model.model.rinna.layers.26.mlp.dense_h_to_4h.bias False
base_model.model.rinna.layers.26.mlp.dense_4h_to_h.weight False
base_model.model.rinna.layers.26.mlp.dense_4h_to_h.bias False
base_model.model.rinna.layers.27.input_layernorm.weight False
base_model.model.rinna.layers.27.input_layernorm.bias False
base_model.model.rinna.layers.27.post_attention_layernorm.weight False
base_model.model.rinna.layers.27.post_attention_layernorm.bias False
base_model.model.rinna.layers.27.attention.query_key_value.weight False
base_model.model.rinna.layers.27.attention.query_key_value.bias False
base_model.model.rinna.layers.27.attention.query_key_value.lora_A.default.weight False
base_model.model.rinna.layers.27.attention.query_key_value.lora_B.default.weight False
base_model.model.rinna.layers.27.attention.dense.weight False
base_model.model.rinna.layers.27.attention.dense.bias False
base_model.model.rinna.layers.27.mlp.dense_h_to_4h.weight False
base_model.model.rinna.layers.27.mlp.dense_h_to_4h.bias False
base_model.model.rinna.layers.27.mlp.dense_4h_to_h.weight False
base_model.model.rinna.layers.27.mlp.dense_4h_to_h.bias False
base_model.model.rinna.layers.28.input_layernorm.weight False
base_model.model.rinna.layers.28.input_layernorm.bias False
base_model.model.rinna.layers.28.post_attention_layernorm.weight False
base_model.model.rinna.layers.28.post_attention_layernorm.bias False
base_model.model.rinna.layers.28.attention.query_key_value.weight False
base_model.model.rinna.layers.28.attention.query_key_value.bias False
base_model.model.rinna.layers.28.attention.query_key_value.lora_A.default.weight False
base_model.model.rinna.layers.28.attention.query_key_value.lora_B.default.weight False
base_model.model.rinna.layers.28.attention.dense.weight False
base_model.model.rinna.layers.28.attention.dense.bias False
base_model.model.rinna.layers.28.mlp.dense_h_to_4h.weight False
base_model.model.rinna.layers.28.mlp.dense_h_to_4h.bias False
base_model.model.rinna.layers.28.mlp.dense_4h_to_h.weight False
base_model.model.rinna.layers.28.mlp.dense_4h_to_h.bias False
base_model.model.rinna.layers.29.input_layernorm.weight False
base_model.model.rinna.layers.29.input_layernorm.bias False
base_model.model.rinna.layers.29.post_attention_layernorm.weight False
base_model.model.rinna.layers.29.post_attention_layernorm.bias False
base_model.model.rinna.layers.29.attention.query_key_value.weight False
base_model.model.rinna.layers.29.attention.query_key_value.bias False
base_model.model.rinna.layers.29.attention.query_key_value.lora_A.default.weight False
base_model.model.rinna.layers.29.attention.query_key_value.lora_B.default.weight False
base_model.model.rinna.layers.29.attention.dense.weight False
base_model.model.rinna.layers.29.attention.dense.bias False
base_model.model.rinna.layers.29.mlp.dense_h_to_4h.weight False
base_model.model.rinna.layers.29.mlp.dense_h_to_4h.bias False
base_model.model.rinna.layers.29.mlp.dense_4h_to_h.weight False
base_model.model.rinna.layers.29.mlp.dense_4h_to_h.bias False
base_model.model.rinna.layers.30.input_layernorm.weight False
base_model.model.rinna.layers.30.input_layernorm.bias False
base_model.model.rinna.layers.30.post_attention_layernorm.weight False
base_model.model.rinna.layers.30.post_attention_layernorm.bias False
base_model.model.rinna.layers.30.attention.query_key_value.weight False
base_model.model.rinna.layers.30.attention.query_key_value.bias False
base_model.model.rinna.layers.30.attention.query_key_value.lora_A.default.weight False
base_model.model.rinna.layers.30.attention.query_key_value.lora_B.default.weight False
base_model.model.rinna.layers.30.attention.dense.weight False
base_model.model.rinna.layers.30.attention.dense.bias False
base_model.model.rinna.layers.30.mlp.dense_h_to_4h.weight False
base_model.model.rinna.layers.30.mlp.dense_h_to_4h.bias False
base_model.model.rinna.layers.30.mlp.dense_4h_to_h.weight False
base_model.model.rinna.layers.30.mlp.dense_4h_to_h.bias False
base_model.model.rinna.layers.31.input_layernorm.weight False
base_model.model.rinna.layers.31.input_layernorm.bias False
base_model.model.rinna.layers.31.post_attention_layernorm.weight False
base_model.model.rinna.layers.31.post_attention_layernorm.bias False
base_model.model.rinna.layers.31.attention.query_key_value.weight False
base_model.model.rinna.layers.31.attention.query_key_value.bias False
base_model.model.rinna.layers.31.attention.query_key_value.lora_A.default.weight False
base_model.model.rinna.layers.31.attention.query_key_value.lora_B.default.weight False
base_model.model.rinna.layers.31.attention.dense.weight False
base_model.model.rinna.layers.31.attention.dense.bias False
base_model.model.rinna.layers.31.mlp.dense_h_to_4h.weight False
base_model.model.rinna.layers.31.mlp.dense_h_to_4h.bias False
base_model.model.rinna.layers.31.mlp.dense_4h_to_h.weight False
base_model.model.rinna.layers.31.mlp.dense_4h_to_h.bias False
base_model.model.rinna.layers.32.input_layernorm.weight False
base_model.model.rinna.layers.32.input_layernorm.bias False
base_model.model.rinna.layers.32.post_attention_layernorm.weight False
base_model.model.rinna.layers.32.post_attention_layernorm.bias False
base_model.model.rinna.layers.32.attention.query_key_value.weight False
base_model.model.rinna.layers.32.attention.query_key_value.bias False
base_model.model.rinna.layers.32.attention.query_key_value.lora_A.default.weight False
base_model.model.rinna.layers.32.attention.query_key_value.lora_B.default.weight False
base_model.model.rinna.layers.32.attention.dense.weight False
base_model.model.rinna.layers.32.attention.dense.bias False
base_model.model.rinna.layers.32.mlp.dense_h_to_4h.weight False
base_model.model.rinna.layers.32.mlp.dense_h_to_4h.bias False
base_model.model.rinna.layers.32.mlp.dense_4h_to_h.weight False
base_model.model.rinna.layers.32.mlp.dense_4h_to_h.bias False
base_model.model.rinna.layers.33.input_layernorm.weight False
base_model.model.rinna.layers.33.input_layernorm.bias False
base_model.model.rinna.layers.33.post_attention_layernorm.weight False
base_model.model.rinna.layers.33.post_attention_layernorm.bias False
base_model.model.rinna.layers.33.attention.query_key_value.weight False
base_model.model.rinna.layers.33.attention.query_key_value.bias False
base_model.model.rinna.layers.33.attention.query_key_value.lora_A.default.weight False
base_model.model.rinna.layers.33.attention.query_key_value.lora_B.default.weight False
base_model.model.rinna.layers.33.attention.dense.weight False
base_model.model.rinna.layers.33.attention.dense.bias False
base_model.model.rinna.layers.33.mlp.dense_h_to_4h.weight False
base_model.model.rinna.layers.33.mlp.dense_h_to_4h.bias False
base_model.model.rinna.layers.33.mlp.dense_4h_to_h.weight False
base_model.model.rinna.layers.33.mlp.dense_4h_to_h.bias False
base_model.model.rinna.layers.34.input_layernorm.weight False
base_model.model.rinna.layers.34.input_layernorm.bias False
base_model.model.rinna.layers.34.post_attention_layernorm.weight False
base_model.model.rinna.layers.34.post_attention_layernorm.bias False
base_model.model.rinna.layers.34.attention.query_key_value.weight False
base_model.model.rinna.layers.34.attention.query_key_value.bias False
base_model.model.rinna.layers.34.attention.query_key_value.lora_A.default.weight False
base_model.model.rinna.layers.34.attention.query_key_value.lora_B.default.weight False
base_model.model.rinna.layers.34.attention.dense.weight False
base_model.model.rinna.layers.34.attention.dense.bias False
base_model.model.rinna.layers.34.mlp.dense_h_to_4h.weight False
base_model.model.rinna.layers.34.mlp.dense_h_to_4h.bias False
base_model.model.rinna.layers.34.mlp.dense_4h_to_h.weight False
base_model.model.rinna.layers.34.mlp.dense_4h_to_h.bias False
base_model.model.rinna.layers.35.input_layernorm.weight False
base_model.model.rinna.layers.35.input_layernorm.bias False
base_model.model.rinna.layers.35.post_attention_layernorm.weight False
base_model.model.rinna.layers.35.post_attention_layernorm.bias False
base_model.model.rinna.layers.35.attention.query_key_value.weight False
base_model.model.rinna.layers.35.attention.query_key_value.bias False
base_model.model.rinna.layers.35.attention.query_key_value.lora_A.default.weight False
base_model.model.rinna.layers.35.attention.query_key_value.lora_B.default.weight False
base_model.model.rinna.layers.35.attention.dense.weight False
base_model.model.rinna.layers.35.attention.dense.bias False
base_model.model.rinna.layers.35.mlp.dense_h_to_4h.weight False
base_model.model.rinna.layers.35.mlp.dense_h_to_4h.bias False
base_model.model.rinna.layers.35.mlp.dense_4h_to_h.weight False
base_model.model.rinna.layers.35.mlp.dense_4h_to_h.bias False
base_model.model.rinna.final_layer_norm.weight False
base_model.model.rinna.final_layer_norm.bias False
base_model.model.my_linear.original_module.weight True
base_model.model.my_linear.original_module.bias True
base_model.model.my_linear.modules_to_save.default.weight True
base_model.model.my_linear.modules_to_save.default.bias True
base_model.model.my_linear2.original_module.weight True
base_model.model.my_linear2.original_module.bias True
base_model.model.my_linear2.modules_to_save.default.weight True
base_model.model.my_linear2.modules_to_save.default.bias True
Progress 0 / 42016
Progress 3200 / 42016
Progress 6400 / 42016
Progress 9600 / 42016
Progress 12800 / 42016
Progress 16000 / 42016
Progress 19200 / 42016
Progress 22400 / 42016
Progress 25600 / 42016
Progress 28800 / 42016
Progress 32000 / 42016
Progress 35200 / 42016
Progress 38400 / 42016
Progress 41600 / 42016
epoch 0 	 loss 509.82813965529203
           correct_num  wrong_num  predict_num  ...  precision  recall      f1
Arg             0.0000        0.0          0.0  ...        NaN     NaN     NaN
Arg0          295.0000       11.0        306.0  ...     0.9641  0.1735  0.2941
Arg1            2.0000       14.0         16.0  ...     0.1250  0.0005  0.0010
Arg2            0.0000        3.0          3.0  ...     0.0000  0.0000     NaN
Arg3            0.0000        0.0          0.0  ...        NaN  0.0000     NaN
Arg4            0.0000        0.0          0.0  ...        NaN  0.0000     NaN
Arg5            0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgA            0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM            0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM2           0.0000        0.0          0.0  ...        NaN     NaN     NaN
ArgM_ADV        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_AND        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_BUT        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_CAU        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_CMP        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_CND        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_CRT        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_DIR        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_EXT        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_GOL        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_LOC        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_MDF        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_MNR        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_MNS        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_NEG        0.0000        1.0          1.0  ...     0.0000  0.0000     NaN
ArgM_PRP        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_PRX        0.0000        3.0          3.0  ...     0.0000  0.0000     NaN
ArgM_REC        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_SCP        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_SPK        0.0000        0.0          0.0  ...        NaN     NaN     NaN
ArgM_TMP        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
sum           297.0000       32.0        329.0  ...     1.0891  0.1740  0.2951
precision       0.9027        NaN          NaN  ...        NaN     NaN     NaN
recall          0.0331        NaN          NaN  ...        NaN     NaN     NaN
f1              0.0639        NaN          NaN  ...        NaN     NaN     NaN
f1_macro        0.0190        NaN          NaN  ...        NaN     NaN     NaN

[36 rows x 8 columns]
Valid f1 =  0.0639 

Progress 0 / 42016
Progress 3200 / 42016
Progress 6400 / 42016
Progress 9600 / 42016
Progress 12800 / 42016
Progress 16000 / 42016
Progress 19200 / 42016
Progress 22400 / 42016
Progress 25600 / 42016
Progress 28800 / 42016
Progress 32000 / 42016
Progress 35200 / 42016
Progress 38400 / 42016
Progress 41600 / 42016
epoch 1 	 loss 482.7899125078693
           correct_num  wrong_num  predict_num  ...  precision  recall      f1
Arg             0.0000        0.0          0.0  ...        NaN     NaN     NaN
Arg0          367.0000       15.0        382.0  ...     0.9607  0.2159  0.3525
Arg1            2.0000       16.0         18.0  ...     0.1111  0.0005  0.0010
Arg2            0.0000        3.0          3.0  ...     0.0000  0.0000     NaN
Arg3            0.0000        0.0          0.0  ...        NaN  0.0000     NaN
Arg4            0.0000        0.0          0.0  ...        NaN  0.0000     NaN
Arg5            0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgA            0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM            0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM2           0.0000        0.0          0.0  ...        NaN     NaN     NaN
ArgM_ADV        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_AND        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_BUT        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_CAU        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_CMP        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_CND        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_CRT        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_DIR        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_EXT        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_GOL        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_LOC        0.0000        1.0          1.0  ...     0.0000  0.0000     NaN
ArgM_MDF        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_MNR        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_MNS        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_NEG        0.0000        1.0          1.0  ...     0.0000  0.0000     NaN
ArgM_PRP        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_PRX        0.0000        4.0          4.0  ...     0.0000  0.0000     NaN
ArgM_REC        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_SCP        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_SPK        0.0000        0.0          0.0  ...        NaN     NaN     NaN
ArgM_TMP        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
sum           369.0000       40.0        409.0  ...     1.0718  0.2164  0.3535
precision       0.9022        NaN          NaN  ...        NaN     NaN     NaN
recall          0.0411        NaN          NaN  ...        NaN     NaN     NaN
f1              0.0787        NaN          NaN  ...        NaN     NaN     NaN
f1_macro        0.0228        NaN          NaN  ...        NaN     NaN     NaN

[36 rows x 8 columns]
Valid f1 =  0.0787 

Progress 0 / 42016
Progress 3200 / 42016
Progress 6400 / 42016
Progress 9600 / 42016
Progress 12800 / 42016
Progress 16000 / 42016
Progress 19200 / 42016
Progress 22400 / 42016
Progress 25600 / 42016
Progress 28800 / 42016
Progress 32000 / 42016
Progress 35200 / 42016
Progress 38400 / 42016
Progress 41600 / 42016
epoch 2 	 loss 475.375299569685
           correct_num  wrong_num  predict_num  ...  precision  recall     f1
Arg             0.0000        0.0          0.0  ...        NaN     NaN    NaN
Arg0          304.0000       16.0        320.0  ...     0.9500  0.1788  0.301
Arg1            2.0000       26.0         28.0  ...     0.0714  0.0005  0.001
Arg2            0.0000        4.0          4.0  ...     0.0000  0.0000    NaN
Arg3            0.0000        0.0          0.0  ...        NaN  0.0000    NaN
Arg4            0.0000        0.0          0.0  ...        NaN  0.0000    NaN
Arg5            0.0000        0.0          0.0  ...        NaN  0.0000    NaN
ArgA            0.0000        0.0          0.0  ...        NaN  0.0000    NaN
ArgM            0.0000        0.0          0.0  ...        NaN  0.0000    NaN
ArgM2           0.0000        0.0          0.0  ...        NaN     NaN    NaN
ArgM_ADV        0.0000        0.0          0.0  ...        NaN  0.0000    NaN
ArgM_AND        0.0000        0.0          0.0  ...        NaN  0.0000    NaN
ArgM_BUT        0.0000        0.0          0.0  ...        NaN  0.0000    NaN
ArgM_CAU        0.0000        0.0          0.0  ...        NaN  0.0000    NaN
ArgM_CMP        0.0000        0.0          0.0  ...        NaN  0.0000    NaN
ArgM_CND        0.0000        0.0          0.0  ...        NaN  0.0000    NaN
ArgM_CRT        0.0000        0.0          0.0  ...        NaN  0.0000    NaN
ArgM_DIR        0.0000        0.0          0.0  ...        NaN  0.0000    NaN
ArgM_EXT        0.0000        0.0          0.0  ...        NaN  0.0000    NaN
ArgM_GOL        0.0000        0.0          0.0  ...        NaN  0.0000    NaN
ArgM_LOC        0.0000        1.0          1.0  ...     0.0000  0.0000    NaN
ArgM_MDF        0.0000        0.0          0.0  ...        NaN  0.0000    NaN
ArgM_MNR        0.0000        0.0          0.0  ...        NaN  0.0000    NaN
ArgM_MNS        0.0000        0.0          0.0  ...        NaN  0.0000    NaN
ArgM_NEG        0.0000        1.0          1.0  ...     0.0000  0.0000    NaN
ArgM_PRP        0.0000        0.0          0.0  ...        NaN  0.0000    NaN
ArgM_PRX        0.0000        2.0          2.0  ...     0.0000  0.0000    NaN
ArgM_REC        0.0000        0.0          0.0  ...        NaN  0.0000    NaN
ArgM_SCP        0.0000        0.0          0.0  ...        NaN  0.0000    NaN
ArgM_SPK        0.0000        0.0          0.0  ...        NaN     NaN    NaN
ArgM_TMP        0.0000        0.0          0.0  ...        NaN  0.0000    NaN
sum           306.0000       50.0        356.0  ...     1.0214  0.1793  0.302
precision       0.8596        NaN          NaN  ...        NaN     NaN    NaN
recall          0.0341        NaN          NaN  ...        NaN     NaN    NaN
f1              0.0656        NaN          NaN  ...        NaN     NaN    NaN
f1_macro        0.0195        NaN          NaN  ...        NaN     NaN    NaN

[36 rows x 8 columns]
No change in valid f1

Progress 0 / 42016
Progress 3200 / 42016
Progress 6400 / 42016
Progress 9600 / 42016
Progress 12800 / 42016
Progress 16000 / 42016
Progress 19200 / 42016
Progress 22400 / 42016
Progress 25600 / 42016
Progress 28800 / 42016
Progress 32000 / 42016
Progress 35200 / 42016
Progress 38400 / 42016
Progress 41600 / 42016
epoch 3 	 loss 469.6180291855708
           correct_num  wrong_num  predict_num  ...  precision  recall      f1
Arg             0.0000        0.0          0.0  ...        NaN     NaN     NaN
Arg0          306.0000       14.0        320.0  ...     0.9562  0.1800  0.3030
Arg1            3.0000       32.0         35.0  ...     0.0857  0.0007  0.0015
Arg2            0.0000        9.0          9.0  ...     0.0000  0.0000     NaN
Arg3            0.0000        0.0          0.0  ...        NaN  0.0000     NaN
Arg4            0.0000        0.0          0.0  ...        NaN  0.0000     NaN
Arg5            0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgA            0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM            0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM2           0.0000        0.0          0.0  ...        NaN     NaN     NaN
ArgM_ADV        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_AND        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_BUT        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_CAU        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_CMP        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_CND        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_CRT        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_DIR        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_EXT        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_GOL        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_LOC        0.0000        1.0          1.0  ...     0.0000  0.0000     NaN
ArgM_MDF        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_MNR        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_MNS        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_NEG        0.0000        1.0          1.0  ...     0.0000  0.0000     NaN
ArgM_PRP        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_PRX        0.0000        4.0          4.0  ...     0.0000  0.0000     NaN
ArgM_REC        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_SCP        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_SPK        0.0000        0.0          0.0  ...        NaN     NaN     NaN
ArgM_TMP        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
sum           309.0000       61.0        370.0  ...     1.0420  0.1807  0.3044
precision       0.8351        NaN          NaN  ...        NaN     NaN     NaN
recall          0.0345        NaN          NaN  ...        NaN     NaN     NaN
f1              0.0662        NaN          NaN  ...        NaN     NaN     NaN
f1_macro        0.0196        NaN          NaN  ...        NaN     NaN     NaN

[36 rows x 8 columns]
No change in valid f1

Progress 0 / 42016
Progress 3200 / 42016
Progress 6400 / 42016
Progress 9600 / 42016
Progress 12800 / 42016
Progress 16000 / 42016
Progress 19200 / 42016
Progress 22400 / 42016
Progress 25600 / 42016
Progress 28800 / 42016
Progress 32000 / 42016
Progress 35200 / 42016
Progress 38400 / 42016
Progress 41600 / 42016
epoch 4 	 loss 464.5325849438086
           correct_num  wrong_num  predict_num  ...  precision  recall      f1
Arg             0.0000        0.0          0.0  ...        NaN     NaN     NaN
Arg0          277.0000       16.0        293.0  ...     0.9454  0.1629  0.2780
Arg1            3.0000       30.0         33.0  ...     0.0909  0.0007  0.0015
Arg2            0.0000       12.0         12.0  ...     0.0000  0.0000     NaN
Arg3            0.0000        0.0          0.0  ...        NaN  0.0000     NaN
Arg4            0.0000        0.0          0.0  ...        NaN  0.0000     NaN
Arg5            0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgA            0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM            0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM2           0.0000        0.0          0.0  ...        NaN     NaN     NaN
ArgM_ADV        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_AND        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_BUT        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_CAU        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_CMP        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_CND        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_CRT        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_DIR        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_EXT        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_GOL        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_LOC        0.0000        1.0          1.0  ...     0.0000  0.0000     NaN
ArgM_MDF        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_MNR        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_MNS        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_NEG        0.0000        1.0          1.0  ...     0.0000  0.0000     NaN
ArgM_PRP        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_PRX        0.0000        4.0          4.0  ...     0.0000  0.0000     NaN
ArgM_REC        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_SCP        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
ArgM_SPK        0.0000        0.0          0.0  ...        NaN     NaN     NaN
ArgM_TMP        0.0000        0.0          0.0  ...        NaN  0.0000     NaN
sum           280.0000       64.0        344.0  ...     1.0363  0.1637  0.2794
precision       0.8140        NaN          NaN  ...        NaN     NaN     NaN
recall          0.0312        NaN          NaN  ...        NaN     NaN     NaN
f1              0.0601        NaN          NaN  ...        NaN     NaN     NaN
f1_macro        0.0180        NaN          NaN  ...        NaN     NaN     NaN

[36 rows x 8 columns]
No change in valid f1

Progress 0 / 42016
Progress 3200 / 42016
Progress 6400 / 42016
Progress 9600 / 42016
Progress 12800 / 42016
Progress 16000 / 42016
Progress 19200 / 42016
Progress 22400 / 42016
Progress 25600 / 42016
Progress 28800 / 42016
Progress 32000 / 42016
Progress 35200 / 42016
Progress 38400 / 42016
